---
title: "STP598sta: Spatiotemporal Analysis"
subtitle: "Hierarchical Modeling of Spatial Data"
author: "Shiwei Lan"
date: Fall 2020
output:
  html_document:
    fontsize: 16pt
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(message = FALSE)
options(width = 1000)
```

In lecture 5, we have learned hierarchical spatial modeles for both Gaussian data and non-Gaussian data.
We will fit hierarchical models using `R` package `spBayes`.

```{r, eval=FALSE}
install.packages('spBayes')
install.packages('fields')
install.packages('MBA')
install.packages('rgdal')
```

## Gaussian spatial regression models

Let's look at forest inventory data from the U.S. Department of Agriculture Forest Service, Bartlett Experimental Forest (BEF), Bartlett, NH.
This dataset is a part of the `spBayes` package in `R` and holds 1991 and 2002 forest inventory data for 437 plots.

we use log-transformed total tree biomass as the outcome and regress it on five predictors

* slope
* elevation
* tasseled cap brightness (TC1)
* greenness (TC2)
* wetness (TC3) components from spring, summer, and fall 2002 Landsat images.

We will use these data to

* demonstrate some basics of univariate spatial regression analysis for Gaussian outcomes.
* and make prediction of biomass for every image pixel across the BEF.

For the illustrations and graphics below, we will load the following packages

```{r}
library(spBayes)
library(MBA)
library(geoR)
library(fields)
library(sp)
library(maptools)
library(rgdal)
library(classInt)
library(lattice)
```

We first do some data exploratory.

```{r, fig.height = 5, fig.width = 9}
## Data preliminaries
data(BEF.dat)
BEF.dat <- BEF.dat[BEF.dat$ALLBIO02_KGH>0,]
bio <- BEF.dat$ALLBIO02_KGH*0.001;
log.bio <- log(bio)
## Extract the coordinates
coords <- as.matrix(BEF.dat[,c("XUTM","YUTM")])

## Make a surface plot
x.res <- 100; y.res <- 100

surf <- mba.surf(cbind(coords, bio), no.X=x.res, no.Y=y.res, h=5, m=2, extend=FALSE)$xyz.est
image.plot(surf, xaxs = "r", yaxs = "r", xlab="Easting (m)", ylab="Northing (m)")
points(coords)
```

### Model Fit

Next, we obtained estimates of the partial sill ($\sigma^2$), nugget ($\tau^2$) and range ($\phi$) based pon some empirical semivariogram plots and used them as starting values in the `spBayes` univariate spatial regression functions `bayesGeostatExact` and `spLM`.
The `bayesGeostatExact` function assumes that $\phi$ and the nugget to partial sill ratio $\tau^2/\sigma^2$ are fixed.
We assume a normal prior on the regression coefficients $\boldsymbol{\beta}$ and an inverse gamma prior on $\sigma^2$.
This leads to tractable posteriors due to conjugacy. Therefore, all posterior samples are directly obtained without MCMC sampling.

```{r}
p <- 6 ## This is the number of columns in the design matrix
## Set the prior mean and precision for the regression
beta.prior.mean <- as.matrix(rep(0, times=p))
beta.prior.precision <- matrix(0, nrow=p, ncol=p)

## For use with bayesGeostatExact, do the following
phi <- 0.014 ## Set the spatial range (from the variogram)
alpha <- 0.016/0.08 ## Set the nugget/partial-sill ratio
sigma.sq.prior.shape <- 2.0 ## Set IG shape for sigma.sq (partial sill)
sigma.sq.prior.rate <- 0.08 ## Set IG scale for sigma.sq (partial sill)

## Run bayesGeostatExact to deliver exact posterior samples
sp.exact <- bayesGeostatExact(
log.bio~ELEV+SLOPE+SUM_02_TC1+SUM_02_TC2+SUM_02_TC3,
data=BEF.dat, coords=coords, n.samples=1000,
beta.prior.mean=beta.prior.mean,
beta.prior.precision=beta.prior.precision,
cov.model="exponential",
phi=phi, alpha=alpha,
sigma.sq.prior.shape=sigma.sq.prior.shape,
sigma.sq.prior.rate=sigma.sq.prior.rate,
sp.effects=FALSE)

##Produce the posterior summaries
round(summary(sp.exact$p.samples)$quantiles,3)
```

A more flexible alternative to `bayesGeostatExact` is the `spLM` function.
The latter does not assume that $phi$ is fixed, nor is it assumed that the ratio $\tau^2/\sigma^2$ is fixed.
Now, we can assign individual priors on $\sigma^2$, $\tau^2$ and $\phi$. In addition, we will now implement MCMC.

The `spLM` function fits the marginalized model, where the spatial effects as well as the regression coefficients have been integrated out. We will see later how these spatial effects can be recovered using the `spRecover` function. 

The regression coefficients are updated from their normal full conditional distrbutions, while the $\sigma^2$, $\tau^2$ and $\phi$ will be updated using Metropolis steps.

```{r}
library(coda)
## Run spLM to deliver MCMC samples from marginal posterior distributions
n.samples <- 1000
bef.sp <- spLM(log.bio~ELEV+SLOPE+SUM_02_TC1+SUM_02_TC2+SUM_02_TC3,
data=BEF.dat, coords=coords, starting=list("phi"=3/200,"sigma.sq"=0.08,
"tau.sq"=0.02), tuning=list("phi"=0.1, "sigma.sq"=0.05, "tau.sq"=0.05),
               priors=list("phi.Unif"=c(3/1500, 3/50), "sigma.sq.IG"=c(2, 0.08),"tau.sq.IG"=c(2, 0.02)), cov.model="exponential",n.samples=n.samples)

round(summary(mcmc(bef.sp$p.theta.samples))$quantiles,3)
```

Note that we have not specified a prior distribution for the regression coefficients $\boldsymbol{\beta}$; a flat prior is used by default.
The `spRecover` function uses composition sampling to obtain the posterior samples of the marginalized regression coefficients and the spatial effects.

```{r}
## Recover spatial residuals using spRecover
burn.in <- floor(0.75*n.samples)
bef.sp <- spRecover(bef.sp, start=burn.in, thin=2)

## The posterior samples of the regression coefficients and the spatial effects can then be obtained as
beta.samples = bef.sp$p.beta.recover.samples
w.samples = bef.sp$p.w.recover.samples
```

The output from spLM is easily exported to the `CODA` package in `R` for convergence diagnostics. For example, if we wish to generate trace plots of the six regression coefficients (including the intercept), we execute

```{r, fig.height = 5, fig.width = 9}
## Obtain trace plots for regression coefficients
par(mfrow=c(3,2))
plot(beta.samples, auto.layout=TRUE, density=FALSE)
```

We could also obtain the posterior mean and standard deviation for the spatial effects as below.
These posterior means can then be interpolated across the domain to produce ``maps" of spatial variables. Assuming that we have already obtained the residuals from a simple ordinary least squares (OLS) model, and stored them in the object `bio.resid`, we plot side by side interpolated surfaces for residuals from the OLS model and for the posterior means of the spatial effects from the spatial regression model.

```{r, fig.height = 5, fig.width = 9}
## Obtain posterior means and sd's of spatial residuals for each location
w.hat.mu <- apply(w.samples,1,mean)
w.hat.sd <- apply(w.samples,1,sd)

## Obtain OLS residuals
lm.bio = lm(log.bio~ELEV+SLOPE+SUM_02_TC1+SUM_02_TC2+SUM_02_TC3, data=BEF.dat)
bio.resid = resid(lm.bio)

## Plot the spatial residual mean surface and a map of sd's
par(mfrow=c(1,2))
surf <- mba.surf(cbind(coords, bio.resid), no.X=x.res, no.Y=y.res, extend=FALSE)$xyz.est
z.lim <- range(surf[[3]], na.rm=TRUE)
image.plot(surf, xaxs = "r", yaxs = "r", zlim=z.lim, main="LM residuals")
surf <- mba.surf(cbind(coords, w.hat.mu), no.X=x.res, no.Y=y.res, extend=FALSE)$xyz.est
image.plot(surf, xaxs = "r", yaxs = "r", zlim=z.lim, main="Mean spatial effects")
```


### Model Prediction

Using the `spLM` object and predictor variables from new locations, the function `spPredict` allows us to sample from the posterior predictive distribution of every pixel across the BEF.

We are only interested in predictions within the BEF; however, the predictor variable grid extends well beyond the BEF bounds. Therefore, we would like to clip the predictor grid to the BEF bounding polygon. The code block below makes use of the `readShapePoly` function from the `maptools` package and `readGDAL` function from the `rgdal` package to read the bounding polygon and predictor variable grid stack, respectively.

```{r}
## Predictions
BEF.shp <- readShapePoly("BEF-data/BEF_bound.shp")
shp2poly <- BEF.shp@polygons[[1]]@Polygons[[1]]@coords
BEF.poly <- as.matrix(shp2poly)
BEF.grids <- readGDAL("BEF-data/dem_slope_lolosptc_clip_60.img")
```

We then construct the prediction design matrix for the entire grid extent. Then extract the coordinates of the BEF bounding polygon vertices and use the `pointsInPoly` `spBayes` function to obtain the desired subset of the prediction design matrix and associated pre- diction coordinates (i.e., pixel centroids). Finally, the `spPredict` function is called and posterior predictive samples are stored in `bef.bio.pred`. The code below implements these steps.

```{r}
## Construct the prediction design matrix for the entire grid extent.
pred.covars <- cbind(BEF.grids[["band1"]], BEF.grids[["band2"]], BEF.grids[["band3"]], BEF.grids[["band4"]], BEF.grids[["band5"]])
pred.covars <- cbind(rep(1, nrow(pred.covars)), pred.covars)


## Extract the coordinates of the BEF bounding polygon vertices and use the pointsInPoly (spBayes) function to obtain the desired subset of the prediction design matrix and associated prediction coordinates (i.e., pixel centroids).
pred.coords <- SpatialPoints(BEF.grids)@coords
pointsInPolyOut <- pointsInPoly(BEF.poly, pred.coords)
pred.covars <- pred.covars[pointsInPolyOut,]
pred.coords <- pred.coords[pointsInPolyOut,]

bef.bio.pred <- spPredict(bef.sp, start=burn.in, thin=2, pred.coords=pred.coords, pred.covars=pred.covars)
```

With access to each pixel's posterior predictive distribution we can map any summary statistics of interest. In the following figure we compare the log metric tons of biomass interpolated over the observed plots to that of the pixel-level prediction. 

The generation of this image plot requires some additional code to clip the interpolation grid produced by `mba.surf` to the BEF polygon. Here we also demonstrate the `sp` function `over` to subset the grid (that is an alternative approach to using `pointsInPoly`).

```{r, fig.height = 5, fig.width = 9}
## Mapping the predicted values
bef.bio.pred.mu = apply(bef.bio.pred$p.y.predictive.samples,1,mean)
bef.bio.pred.sd = apply(bef.bio.pred$p.y.predictive.samples,1,sd)
surf <- mba.surf(cbind(coords, log.bio), no.X=x.res, no.Y=x.res, extend=TRUE, sp=TRUE)$xyz.est
surf <- surf[complete.cases(sp::over(surf, BEF.shp)),]
surf <- as.image.SpatialGridDataFrame(surf)
z.lim <- range(surf[["z"]], na.rm=TRUE)

pred.grid <- as.data.frame(list(pred.coords, pred.mu=bef.bio.pred.mu, pred.sd=bef.bio.pred.sd))
coordinates(pred.grid) = c("x", "y")
gridded(pred.grid) <- TRUE
pred.mu.image <- as.image.SpatialGridDataFrame(pred.grid["pred.mu"])

par(mfrow=c(1,2))
image.plot(surf, axes=TRUE, zlim=z.lim, col=tim.colors(25), xaxs = "r", yaxs = "r", main="Log metric tons of biomass")
plot(BEF.shp, add=TRUE)
image.plot(pred.mu.image, zlim=z.lim, col=tim.colors(25), xaxs = "r", yaxs = "r", main="Mean predicted log metric tons of biomass")
plot(BEF.shp, add=TRUE)
```


## Non-Gaussian spatial GLM

The function `spGLM` fits the Poisson and binomial model using the log and logit link function, respectively. Here we illustrate the use of `spGLM` to fit a Poisson generalized linear mixed model with spatially dependent random effects.

We consider a simulated dataset with 50 locations inside the unit square. We generate a latent Gaussian spatial random field $w({\bf s})$ using an exponential covariance function with $\sigma^2=2$ and $\phi=3/0.5$ (so the spatial range is 0.5). Finally, the outcome in each location is generated from a Poisson distribution with intensity $\exp(\beta_0+w({\bf s}_i))$.

```{r}
##### Spatial GLM #####
library(MASS)
## Generate some count data from each location
n <- 50
coords <- cbind(runif(n, 0, 1), runif(n, 0, 1))
phi <- 3/0.5
sigma.sq <- 2
R <- exp(-phi * iDist(coords))
w <- mvrnorm(1, rep(0, n), sigma.sq * R)
beta.0 <- 0.1
y <- rpois(n, exp(beta.0 + w))
```

Assuming there is no spatial dependence we might fit a simple non-spatial GLM using

```{r}
##First fit a simple non-spatial GLM:
pois.nonsp <- glm(y ~ 1, family = "poisson")
beta.starting <- coefficients(pois.nonsp)
beta.tuning <- t(chol(vcov(pois.nonsp)))
```

These coefficients and the Cholesky square root of the parameters' estimated covariances will be used as starting values and Metropolis sampler tuning values in the subsequent call to `spGLM`. In addition to the regression coefficients we specify starting values for the spatial range `phi` and variance `sigma.sq` as well as the random spatial effects `w`.

```{r}
## Here posterior inference is based on three MCMC chains each of length 15,000. The code to generate the first of these chains is given below.
n.batch <- 300
batch.length <- 50
n.samples <- n.batch * batch.length
pois.sp.chain.1 <-
spGLM(y ~ 1,family = "poisson",coords = coords,
starting = list(beta = beta.starting,
phi = 3/0.5,
sigma.sq = 1,w = 0),
tuning = list(beta = 0.1, phi = 0.5,
sigma.sq = 0.1,w = 0.1),
priors = list("beta.Flat",
phi.Unif = c(3/1, 3/0.1),
sigma.sq.IG = c(2, 1)),
amcmc = list(n.batch = n.batch,
batch.length=batch.length,
accept.rate = 0.43),
cov.model = "exponential")
```

The coda package’s plot function can be used to plot chain trace plot. And we can also do some analysis of the posterior samples.

```{r, fig.height = 5, fig.width = 9}
samps <- mcmc.list(pois.sp.chain.1$p.beta.theta.samples)
plot(samps)

##print(gelman.diag(samps))
##gelman.plot(samps)
burn.in <- 10000
print(round(summary(window(samps, start = burn.in))$quantiles[,c(3, 1, 5)], 2))
```

Given the post burn-in samples, we can also generate surfaces of the estimated counts.

```{r, fig.height = 5, fig.width = 9}
samps <- as.matrix(window(samps, start = burn.in))
w <- cbind(pois.sp.chain.1$p.w.samples[, burn.in:n.samples])
beta.0.hat <- mean(samps[, "(Intercept)"])
w.hat <- apply(w, 1, mean)
y.hat <- exp(beta.0.hat + w.hat)

## Map the predicted counts and associated standard errors
par(mfrow = c(1, 2))
surf <- mba.surf(cbind(coords, y), no.X = 100, no.Y = 100, extend = TRUE)$xyz.est
image.plot(surf, main = "Observed counts")
points(coords)
surf <- mba.surf(cbind(coords, y.hat), no.X = 100, no.Y = 100, extend = TRUE)$xyz.est
image.plot(surf, main = "Fitted counts")
points(coords)
```



